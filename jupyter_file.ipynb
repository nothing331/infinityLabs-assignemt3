{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9708b-2b31-47df-89c1-f602f18f50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe64f2c-0333-416b-843e-22a47c25b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_Annotations_folder = \"VOCdevkit\\VOC2011\\Annotations\"  # Replace with the actual path\n",
    "Annotations_files = os.listdir(category_Annotations_folder)\n",
    "num_selected_A = int(len(Annotations_files))\n",
    "\n",
    "Annotations[]\n",
    "\n",
    " for Annotations in num_selected_A:\n",
    "     full_Annotations = os.path.join(category_Annotations_folder, Annotations)\n",
    "     Annotations.append(full_Annotations)\n",
    "\n",
    "# category_B1_folder = \"VOCdevkit\\VOC2011\\ImageSets\\Action\" \n",
    "# image_files_B1 = os.listdir(category_B1_folder)\n",
    "# num_selected_B1 = int(len(image_files_B1) * 0.1)\n",
    "# selected_images_B1 = random.sample(image_files_B1, num_selected_B1)\n",
    "\n",
    "\n",
    "# category_B2_folder = \"VOCdevkit\\VOC2011\\ImageSets\\Layout\" \n",
    "# image_files_B2 = os.listdir(category_B2_folder)\n",
    "# num_selected_B2 = int(len(image_files_B2) * 0.1)\n",
    "# selected_images_B2 = random.sample(image_files_B2, num_selected_B2)\n",
    "\n",
    "\n",
    "# category_B3_folder = \"VOCdevkit\\VOC2011\\ImageSets\\Main\" \n",
    "# image_files_B3 = os.listdir(category_B3_folder)\n",
    "# num_selected_B3 = int(len(image_files_B3) * 0.1)\n",
    "# selected_images_B3 = random.sample(image_files_B3, num_selected_B3)\n",
    "\n",
    "\n",
    "# category_B4_folder = \"VOCdevkit\\VOC2011\\ImageSets\\Segmentation\" \n",
    "# image_files_B4 = os.listdir(category_B4_folder)\n",
    "# num_selected_B4 = int(len(image_files_B4) * 0.1)\n",
    "# selected_images_B4 = random.sample(image_files_B4, num_selected_B4)\n",
    "# selected_images_B4\n",
    "\n",
    "\n",
    "category_A_folder = \"VOCdevkit\\VOC2011\\JPEGImages\" \n",
    "image_files_A = os.listdir(category_A_folder)\n",
    "num_selected_A = random.randint(int(len(image_files_A) * 0.2), int(len(image_files_A) * 0.5))\n",
    "selected_images_A = random.sample(image_files_A, num_selected_A)\n",
    "\n",
    "category_B_folder = \"VOCdevkit\\VOC2011\\SegmentationClass\" \n",
    "image_files_B = os.listdir(category_B_folder)\n",
    "num_selected_B = int(len(image_files_B) * 0.1)\n",
    "selected_images_B = random.sample(image_files_B, num_selected_B)\n",
    "\n",
    "\n",
    "category_C_folder = \"VOCdevkit\\VOC2011\\SegmentationObject\" \n",
    "image_files_C = os.listdir(category_C_folder)\n",
    "num_selected_C = int(len(image_files_C) * 0.1)\n",
    "selected_images_C = random.sample(image_files_C, num_selected_C)\n",
    "selected_images_C\n",
    "\n",
    "not_A = []\n",
    "# for image_path in selected_images_B1:\n",
    "#     full_image_path = os.path.join(category_B1_folder, image_path)\n",
    "#     not_A.append(full_image_path)\n",
    "\n",
    "# for image_path in selected_images_B2:\n",
    "#     full_image_path = os.path.join(category_B2_folder, image_path)\n",
    "#     not_A.append(full_image_path)\n",
    "\n",
    "# for image_path in selected_images_B3:\n",
    "#     full_image_path = os.path.join(category_B3_folder, image_path)\n",
    "#     not_A.append(full_image_path)\n",
    "\n",
    "# for image_path in selected_images_B4:\n",
    "#     full_image_path = os.path.join(category_B4_folder, image_path)\n",
    "#     not_A.append(full_image_path)\n",
    "\n",
    "for image_path in selected_images_C:\n",
    "    full_image_path = os.path.join(category_C_folder, image_path)\n",
    "    not_A.append(image_path)\n",
    "\n",
    "for image_path in selected_images_B:\n",
    "    full_image_path = os.path.join(category_B_folder, image_path)\n",
    "    not_A.append(image_path)\n",
    "\n",
    "only_A =[]\n",
    "for image_path in selected_images_A:\n",
    "    full_image_path = os.path.join(category_A_folder, image_path)\n",
    "    only_A.append(image_path)\n",
    "\n",
    "\n",
    "\n",
    "training_dataset = []\n",
    "for image_path in not_A :\n",
    "    training_dataset.append(image_path)\n",
    "\n",
    "for image_path in only_A :\n",
    "    training_dataset.append(image_path)\n",
    "\n",
    "\n",
    "\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008ea4a-050d-497a-a814-e4698c21f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet-50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Define image preprocessing transformations\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# List to store feature vectors for selected images\n",
    "feature_vectors = []\n",
    "labels_valid = []\n",
    "\n",
    "# Process and extract features for each selected image\n",
    "for image_path in training_dataset:  # Use the training dataset created in Step 3\n",
    "    # Load and preprocess the image\n",
    "    img_array = preprocess_image(image_path)\n",
    "    \n",
    "    # Expand dimensions to match ResNet-50 input shape (batch size 1)\n",
    "    img_array = tf.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Extract features using the model\n",
    "    features = model.predict(img_array)\n",
    "\n",
    "    # Append the feature tensor to the list\n",
    "    feature_vectors.append(features)\n",
    "\n",
    "    label = image_path\n",
    "    labels_valid.append(label)\n",
    "\n",
    "# Stack the feature tensors into a single tensor\n",
    "feature_matrix = tf.concat(feature_vectors, axis=0)\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed7722-65a7-413b-a393-a8d7301834f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet-50 model \n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# preprocessing function\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# List to store feature vectors for selected images\n",
    "feature_vectors = []\n",
    "labels = []\n",
    "\n",
    "# Specify the path to your image folder and annotations folder\n",
    "image_folder = \"VOCdevkit\\VOC2011\\JPEGImages\"\n",
    "annotations_folder = \"VOCdevkit\\VOC2011\\Annotations\"\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    # Load and preprocess the image\n",
    "    img_path = os.path.join(image_folder, filename)\n",
    "    img_array = preprocess_image(img_path)\n",
    "\n",
    "    # Forward pass through the model to extract features\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
    "    features = model.predict(img_array)\n",
    "\n",
    "    # Adding to the feature_vectors array\n",
    "    feature_vectors.append(features)\n",
    "\n",
    "    # Load the corresponding label from annotations\n",
    "    label_filename = os.path.splitext(filename)[0] + \".xml\" \n",
    "    label_path = os.path.join(annotations_folder, label_filename)\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        label = label_file.read().strip()  # Searching the files in annotation floder\n",
    "        labels.append(label)\n",
    "\n",
    "feature_matrix = np.vstack(feature_vectors)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40e735-7c32-4933-8118-dae4bffb38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = training_dataset  # List of image file paths\n",
    "all_labels = Annotations  # List of corresponding labels\n",
    "\n",
    "# thaking data used for validation as 20%\n",
    "validation_fraction = 0.2\n",
    "\n",
    "\n",
    "num_validation_samples = int(len(all_image_paths) * validation_fraction)\n",
    "\n",
    "combined = list(zip(all_image_paths, all_labels))\n",
    "random.shuffle(combined)\n",
    "all_image_paths[:], all_labels[:] = zip(*combined)\n",
    "\n",
    "validation_image_paths = all_image_paths[:num_validation_samples]\n",
    "validation_labels = all_labels[:num_validation_samples]\n",
    "\n",
    "feature_vectors_valid = []\n",
    "\n",
    "for image_path in validation_image_paths:\n",
    "    img_array = preprocess_image(image_path)\n",
    "    \n",
    "    img_array = tf.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    features = model.predict(img_array)\n",
    "    \n",
    "    feature_vectors_valid.append(features)\n",
    "\n",
    "feature_matrix_valid = tf.concat(feature_vectors_valid, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0166c3de-94e6-4dfc-8d40-872b531770f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m knn_classifier \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the k-NN classifier on the training data\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m knn_classifier\u001b[38;5;241m.\u001b[39mfit(\u001b[43mfeature_matrix\u001b[49m, labels)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Predict labels for validation set\u001b[39;00m\n\u001b[0;32m     12\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m knn_classifier\u001b[38;5;241m.\u001b[39mpredict(feature_matrix_valid)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Creating an k-NN classifier \n",
    "k = 5  # Number of neighbors\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Train the k-NN classifier on the training data\n",
    "knn_classifier.fit(feature_matrix, labels)\n",
    "\n",
    "# Predict labels for validation set\n",
    "predicted_labels = knn_classifier.predict(feature_matrix_valid)\n",
    "\n",
    "# Calculate classification accuracy\n",
    "accuracy = accuracy_score(labels_valid, predicted_labels)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613eeb6-c846-4896-88b7-178d83028f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
